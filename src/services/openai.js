const MASTER_AI_KEY = import.meta.env.VITE_OPENAI_API_KEY;

class OpenAIService {
    async generateSuggestion({ clientName, history, briefing, extraContext = "" }) {
        const openaiKey = MASTER_AI_KEY;
        const systemPrompt = `
Voc√™ √© o Especialista de Vendas AURA v10 da VoxeFlow. Sua miss√£o n√£o √© apenas responder, mas CONECTAR e CONVERTER atrav√©s de uma comunica√ß√£o humana, emp√°tica e estrategicamente brilhante.

BASE DE CONHECIMENTO DO NEG√ìCIO (SANTU√ÅRIO DE VERDADE):
${briefing}

${extraContext ? `DADOS T√âCNICOS DO ESPECIALISTA (RAG): ${extraContext}` : ''}

üö® PROIBI√á√ïES ABSOLUTAS (LEIA COM ATEN√á√ÉO):
1. NUNCA diga "n√£o sei", "n√£o tenho essa informa√ß√£o" ou "vou verificar".
2. SE a informa√ß√£o n√£o estiver na "BASE DE CONHECIMENTO", voc√™ √â OBRIGADO a usar a tag [KNOWLEDGE_GAP].
3. N√ÉO invente pre√ßos ou marcas.

DIRETRIZES DE COMUNICA√á√ÉO ELITE:
1. ü§ù RAPPORT & CALIBRAGEM: Identifique e espelhe o tom do cliente.
2. üß† SPIN SELLING: Use Situa√ß√£o, Problema, Implica√ß√£o, Necessidade.
3. üñãÔ∏è HUMAN-FIRST: Seja gentil e termine com pergunta.
`.trim();

        // 1. Prepare Messages
        const messages = [{ role: 'system', content: systemPrompt }];
        if (Array.isArray(history)) messages.push(...history);
        messages.push({
            role: 'user',
            content: `Gere uma resposta calorosa, humana e profissional para ${clientName}.
            
            üß† PROTOCOLO DE LACUNA (OBRIGAT√ìRIO):
            Se o cliente perguntou algo que N√ÉO est√° na Base de Conhecimento, RESPONDA APENAS:
            [KNOWLEDGE_GAP: {Sua pergunta curta para o dono do neg√≥cio}]

            Exemplo:
            Cliente: "Aceita Bitcoin?"
            Base: (N√£o diz nada sobre Bitcoin)
            Sua Resposta: [KNOWLEDGE_GAP: Aceitamos Bitcoin ou criptomoedas?]`
        });

        const payload = {
            model: 'gpt-4o',
            messages: messages,
            temperature: 0.5,
            max_tokens: 350
        };

        // HYBRID STRATEGY: Try Proxy first, then Direct Fallback
        try {
            const response = await fetch('/api/ai', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (response.ok) {
                const data = await response.json();
                if (!data.error) {
                    let result = data.choices[0].message.content.trim();
                    return result.replace(/^(Empresa|Aura|Vendedor|Assistant|Atendente):\s*/i, '');
                }
            }
            throw new Error(`Proxy failed: ${response.status}`);
        } catch (proxyError) {
            console.warn("AURA: Proxy failed, attempting direct client-side fallback...", proxyError);
            if (openaiKey) {
                try {
                    const response = await fetch('https://api.openai.com/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': `Bearer ${openaiKey}`
                        },
                        body: JSON.stringify(payload)
                    });
                    const data = await response.json();
                    if (!data.error) {
                        return data.choices[0].message.content.trim();
                    }
                } catch (directError) {
                    console.error("AURA: Direct fallback also failed.", directError);
                }
            }
            return null;
        }
    }

    async enhanceMessage(text, context = {}) {
        const openaiKey = MASTER_AI_KEY;
        const systemPrompt = `
            Voc√™ √© o Consultor de Vendas S√™nior da AURA. Refine a mensagem para ser mais humana, persuasiva e aplicar SPIN Selling.
            CONTEXTO: ${context.briefing || 'Empresa de Alto Padr√£o'}
            RETORNE APENAS O TEXTO FINAL.
            `.trim();

        const payload = {
            model: 'gpt-4o',
            messages: [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: text }
            ],
            temperature: 0.7,
            max_tokens: 300
        };

        try {
            const response = await fetch('/api/ai', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });
            if (response.ok) {
                const data = await response.json();
                return data.choices[0].message.content.trim();
            }
            throw new Error(`Proxy failed: ${response.status}`);
        } catch (e) {
            if (openaiKey) {
                try {
                    const response = await fetch('https://api.openai.com/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': `Bearer ${openaiKey}`
                        },
                        body: JSON.stringify(payload)
                    });
                    const data = await response.json();
                    return data.choices[0].message.content.trim();
                } catch (dE) { return text; }
            }
            return text;
        }
    }

    async analyzeNextSteps(chatHistory, patientName, currentTag) {
        const openaiKey = MASTER_AI_KEY;
        // Skip check here to try proxy first

        const systemPrompt = `
            Voc√™ √© consultor de vendas EXPERT. Analise a conversa e sugira 2-3 passos PR√ÅTICOS.
            HIST√ìRICO: ${chatHistory}
            RETORNE JSON: { "steps": [], "priority": "high|medium|low", "reasoning": "" }
            `.trim();

        const payload = {
            model: 'gpt-4o',
            messages: [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: 'Analise e sugira os pr√≥ximos passos.' }
            ],
            temperature: 0.7,
            max_tokens: 300,
            response_format: { type: "json_object" }
        };

        const fallbackError = {
            steps: ['Revisar conversa manualmente'],
            priority: 'medium',
            reasoning: 'Erro na an√°lise autom√°tica'
        };

        try {
            const response = await fetch('/api/ai', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });
            if (response.ok) {
                const data = await response.json();
                return JSON.parse(data.choices[0].message.content);
            }
            throw new Error("Proxy error");
        } catch (e) {
            if (openaiKey) {
                try {
                    const response = await fetch('https://api.openai.com/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': `Bearer ${openaiKey}`
                        },
                        body: JSON.stringify(payload)
                    });
                    const data = await response.json();
                    return JSON.parse(data.choices[0].message.content);
                } catch (dE) { return fallbackError; }
            }
            return fallbackError;
        }
    }

    async generateNextBriefingQuestion(currentAnswers) {
        const openaiKey = MASTER_AI_KEY; // Fallback key
        const systemPrompt = `Voc√™ √© o Arquiteto de Intelig√™ncia da AURA. Entreviste o dono do neg√≥cio. Conhecido: ${JSON.stringify(currentAnswers)}. Fa√ßa UMA pergunta por vez. Se acabar, diga COMPLETE.`;

        const payload = {
            model: 'gpt-4o',
            messages: [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: 'Gere a pr√≥xima pergunta ou COMPLETE.' }
            ],
            temperature: 0.7,
            max_tokens: 150
        };

        try {
            const response = await fetch('/api/ai', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });
            if (response.ok) {
                const data = await response.json();
                return data.choices?.[0]?.message?.content?.trim();
            }
            throw new Error('Proxy fail');
        } catch (e) {
            if (openaiKey) {
                try {
                    const response = await fetch('https://api.openai.com/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': `Bearer ${openaiKey}`
                        },
                        body: JSON.stringify(payload)
                    });
                    const data = await response.json();
                    return data.choices?.[0]?.message?.content?.trim();
                } catch (dE) { return "Algum outro detalhe importante?"; }
            }
            return "Algum outro detalhe importante?";
        }
    }

    async analyzeKnowledgePoint(question, answer) {
        const openaiKey = MASTER_AI_KEY;
        const systemPrompt = `Analise este ponto de conhecimento para vendas. Resposta curta (2 linhas).`;
        const payload = {
            model: 'gpt-4o',
            messages: [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: `Pergunta: ${question}\nResposta: ${answer}` }
            ],
            temperature: 0.5,
            max_tokens: 100
        };

        try {
            const response = await fetch('/api/ai', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });
            if (response.ok) {
                const data = await response.json();
                return data.choices?.[0]?.message?.content?.trim();
            }
            throw new Error("Proxy fail");
        } catch (e) {
            if (openaiKey) {
                try {
                    const response = await fetch('https://api.openai.com/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': `Bearer ${openaiKey}`
                        },
                        body: JSON.stringify(payload)
                    });
                    const data = await response.json();
                    return data.choices?.[0]?.message?.content?.trim();
                } catch (dE) { return "Ponto estrat√©gico validado."; }
            }
            return "Ponto estrat√©gico validado.";
        }
    }
}

export default new OpenAIService();
